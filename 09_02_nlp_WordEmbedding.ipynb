{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_02_nlp_WordEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgYqpBEtCrtR"
      },
      "source": [
        "# Word Embeddings and Sentiment\n",
        "\n",
        "\n",
        "Embeddings are `clusters of vectors in multi-dimensional space`, where each vector represents a given word in those dimensions. \n",
        "\n",
        "While it’s difficult for us humans to think in many dimensions, luckily the **TensorFlow Projector** <http://projector.tensorflow.org/> makes it fairly easy for us to view these clusters in a 3D projection (later Colabs will generate the necessary files for use with the projection tool)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLnyQ0oGDVJs"
      },
      "source": [
        "# Building a Basic Sentiment Model\n",
        "\n",
        "- To create our embeddings, we’ll first use an embeddings layer, called tf.keras.layers.Embedding.\n",
        "    - It takes 3 arguments:\n",
        "      1. the size of the tokenized vocabulary\n",
        "      2. the number of embedding dimensions to use, \n",
        "      3. the input length (from when you standardized sequence length with padding and truncation).\n",
        "\n",
        "The output of this layer needs to be reshaped to work with any fully-connected layers. \n",
        "You can do this with a pure Flatten layer, or use GlobalAveragePooling1D for a little additional computation that sometimes creates better results.\n",
        "\n",
        "In our case, we’re only looking at positive vs. negative sentiment, so only a single output node is needed (0 for negative, 1 for positive). You’ll be able to use a binary cross entropy loss function since the result is only binary classification.\n",
        "\n",
        "**Given a vocabulary size of 500, maximum sequence length of 50, and embedding dimension of 16, what is the output shape of the Embedding layer?**\n",
        "\n",
        "(None,50,16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMUDLgNEOZJ"
      },
      "source": [
        "# A Note on Embedding Networks\n",
        "\n",
        "The TensorFlow team has two additional suggestions:\n",
        "\n",
        "1.They suggest that the final network does not use a sigmoid activation layer when working with embeddings, especially when using just the two classes like we are for sentiment analysis:tf.keras.layers.Dense(1)\n",
        "\n",
        "2.Additionally, they suggest instead of using the string binary_crossentropy as the loss function, you use tf.keras.losses.BinaryCrossentropy(from_logits=True)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z0JDiLc8dkE"
      },
      "source": [
        "# Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74n4IodoHV5a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IHaLk0n8tde"
      },
      "source": [
        "## Get the dataset\n",
        "\n",
        "We're going to use a dataset containing Amazon and Yelp reviews, with their related sentiment (1 for positive, 0 for negative). This dataset was originally extracted from [here](https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29VT-oCQ8scF",
        "outputId": "af6955d2-cbe4-48b6-80c9-b323ed71a732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    -O /tmp/sentiment.csv https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-09 15:22:25--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.99.113, 142.250.99.100, 142.250.99.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.99.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g3neebfvip4euf0b05nj13n53201a2tv/1602256875000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-10-09 15:22:25--  https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/g3neebfvip4euf0b05nj13n53201a2tv/1602256875000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
            "Resolving doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127831 (125K) [text/csv]\n",
            "Saving to: ‘/tmp/sentiment.csv’\n",
            "\n",
            "/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-10-09 15:22:26 (115 MB/s) - ‘/tmp/sentiment.csv’ saved [127831/127831]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZGcHedi9L6e",
        "outputId": "95334c2c-dc54-4f07-9caa-59c2903fce58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/tmp/sentiment.csv')\n",
        "print(dataset.shape)\n",
        "dataset.tail()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1992, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>1987</td>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>1988</td>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>1989</td>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>1990</td>\n",
              "      <td>The whole experience was underwhelming and I t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>1991</td>\n",
              "      <td>Then as if I hadn't wasted enough of my life t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                               text  sentiment\n",
              "1987        1987  I think food should have flavor and texture an...          0\n",
              "1988        1988                           Appetite instantly gone.          0\n",
              "1989        1989  Overall I was not impressed and would not go b...          0\n",
              "1990        1990  The whole experience was underwhelming and I t...          0\n",
              "1991        1991  Then as if I hadn't wasted enough of my life t...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKatsri_9jB-",
        "outputId": "e00553db-d202-419b-8499-5ea20da3382b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sentences =dataset.text.tolist()\n",
        "labels = dataset.sentiment.tolist()\n",
        "print(sentences[10])\n",
        "print(labels[10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And the sound quality is great.\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuDD6PqO99sd"
      },
      "source": [
        "# Separate out the sentences and labels into training and test set\n",
        "training_size = int(len(sentences)*0.8)\n",
        "\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]\n",
        "\n",
        "# Make labels into numpy arrays for use with the network later\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX950gwc_AR_",
        "outputId": "448b1d8f-8620-42f2-d2c1-42ea1bdbedeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_labels_final\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btWxzyzO_PRN"
      },
      "source": [
        "# Tokenize the dataset\n",
        "Tokenize the dataset, including padding and OOV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omc4cSE2_BcT"
      },
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size ,oov_token=oov_tok )\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences , maxlen=max_length, padding=padding_type, \n",
        "                       truncating= trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length, padding=padding_type, \n",
        "                       truncating= trunc_type)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahWK15zlA4g8"
      },
      "source": [
        "## Review a Sequence\n",
        "Let's quickly take a look at one of the padded sequences to ensure everything above worked appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ysBgs1Ay6U",
        "outputId": "fcbcb29b-8792-4242-ec88-3097f0f911f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "reverse_word_index = dict([ (value,key) for (key,value) in word_index.items() ])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i,'?') for i in text])\n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(training_sentences[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "good case excellent value ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "Good case Excellent value.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4lIOoXeHL3b",
        "outputId": "c921a553-b0de-4de2-dfb1-c65f43364338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "print(decode_review(padded[10]))\n",
        "print(training_sentences[10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and the sound quality is great ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "And the sound quality is great.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxJxzn8QH526"
      },
      "source": [
        "## Train a Basic Sentiment Model with Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJQoDbfFHcYN",
        "outputId": "bb73e190-b9d6-4c4d-faa9-667669effb49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Build a basic sentiment network\n",
        "# Note the embedding layer is first, \n",
        "# and the output is only 1 node as it is either 0 or 1 (negative or positive)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(6,activation='relu'),\n",
        "                             tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 16)           16000     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 9606      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 25,613\n",
            "Trainable params: 25,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTqVZH6UJBie",
        "outputId": "d4d16da1-c3ab-4de5-852c-2c82dc76b326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_epochs =10\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5235 - val_loss: 0.6957 - val_accuracy: 0.4110\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5229 - val_loss: 0.7001 - val_accuracy: 0.4110\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.5581 - val_loss: 0.6918 - val_accuracy: 0.4436\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6133 - val_loss: 0.6695 - val_accuracy: 0.5514\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7709 - val_loss: 0.5790 - val_accuracy: 0.7268\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.9058 - val_loss: 0.5131 - val_accuracy: 0.7419\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.9259 - val_loss: 0.4723 - val_accuracy: 0.7669\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9479 - val_loss: 0.4822 - val_accuracy: 0.7694\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9699 - val_loss: 0.4736 - val_accuracy: 0.7644\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9736 - val_loss: 0.5125 - val_accuracy: 0.7494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f10dd77dcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypu1zVwXJXV8"
      },
      "source": [
        "## Get files for visualizing the network\n",
        "\n",
        "The code below will download two files for visualizing how your network \"sees\" the sentiment related to each word. Head to http://projector.tensorflow.org/ and load these files, then click the \"Sphereize\" checkbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486P_voDJS9C",
        "outputId": "c832de1c-cd72-4ad2-c969-1bfa233abc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First get the weights of the embedding layer\n",
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM7ShMbQJptR",
        "outputId": "31931e7e-99cf-4f06-f981-5710890c9dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.08513905, -0.07916204,  0.03986736, ...,  0.05990879,\n",
              "        -0.06803873, -0.06323504],\n",
              "       [-0.04556246,  0.03551653, -0.03865337, ..., -0.03001493,\n",
              "        -0.09691637,  0.01935509],\n",
              "       [-0.01136928, -0.07080145,  0.01817639, ...,  0.05674662,\n",
              "         0.02572152,  0.02062324],\n",
              "       ...,\n",
              "       [-0.0203247 , -0.08085664,  0.09329598, ...,  0.02630224,\n",
              "        -0.03243666,  0.05038565],\n",
              "       [-0.0002204 ,  0.10957355,  0.08335437, ..., -0.02368987,\n",
              "        -0.03652238,  0.08833388],\n",
              "       [ 0.1348406 ,  0.00526085,  0.0871685 , ...,  0.05671656,\n",
              "        -0.15233889, -0.07701384]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL44zv7GJqca"
      },
      "source": [
        "import io\n",
        "\n",
        "# Write out the embedding vectors and metadata\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMMeTc2EJy9P",
        "outputId": "11400258-95d1-4744-9870-5d35fa312882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Download the files\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1adf8255-8fec-42b0-a771-30b16a3e28fc\", \"vecs.tsv\", 190647)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9fac0112-8ff0-4f90-bfce-5149ea88f2e8\", \"meta.tsv\", 6617)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-3jdvrMKIyK"
      },
      "source": [
        "## Predicting Sentiment in New Reviews\n",
        "\n",
        "Now that you've trained and visualized your network, take a look below at how we can predict sentiment in new reviews the network has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkER3jL8J2WK",
        "outputId": "5b9dbc92-c213-4002-cc80-251bccde64da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "# Use the model to predict a review   \n",
        "fake_reviews = ['I love this phone', 'I hate spaghetti', \n",
        "                'Everything was cold',\n",
        "                'Everything was hot exactly as I wanted', \n",
        "                'Everything was green', \n",
        "                'the host seated us immediately',\n",
        "                'they gave us free chocolate cake', \n",
        "                'not sure about the wilted flowers on the table',\n",
        "                'only works when I stand on tippy toes', \n",
        "                'does not work when I stand on my head',\n",
        "                'You can\\'t we right for a wrong person and the right one will find your worth',\n",
        "                'Some stories are always destined to be left half way']\n",
        "\n",
        "print(fake_reviews) \n",
        "\n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)           \n",
        "\n",
        "print('\\nHOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\\n')              \n",
        "\n",
        "classes = model.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "for x in range(len(fake_reviews)):\n",
        "  print(fake_reviews[x])\n",
        "  print(classes[x])\n",
        "  print('\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I love this phone', 'I hate spaghetti', 'Everything was cold', 'Everything was hot exactly as I wanted', 'Everything was green', 'the host seated us immediately', 'they gave us free chocolate cake', 'not sure about the wilted flowers on the table', 'only works when I stand on tippy toes', 'does not work when I stand on my head', \"You can't we right for a wrong person and the right one will find your worth\", 'Some stories are always destined to be left half way']\n",
            "\n",
            "HOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\n",
            "\n",
            "I love this phone\n",
            "[0.9975854]\n",
            "\n",
            "\n",
            "I hate spaghetti\n",
            "[0.08118349]\n",
            "\n",
            "\n",
            "Everything was cold\n",
            "[0.5009543]\n",
            "\n",
            "\n",
            "Everything was hot exactly as I wanted\n",
            "[0.63833845]\n",
            "\n",
            "\n",
            "Everything was green\n",
            "[0.5471215]\n",
            "\n",
            "\n",
            "the host seated us immediately\n",
            "[0.6866338]\n",
            "\n",
            "\n",
            "they gave us free chocolate cake\n",
            "[0.9074721]\n",
            "\n",
            "\n",
            "not sure about the wilted flowers on the table\n",
            "[0.02860391]\n",
            "\n",
            "\n",
            "only works when I stand on tippy toes\n",
            "[0.9821178]\n",
            "\n",
            "\n",
            "does not work when I stand on my head\n",
            "[0.01599413]\n",
            "\n",
            "\n",
            "You can't we right for a wrong person and the right one will find your worth\n",
            "[0.71696866]\n",
            "\n",
            "\n",
            "Some stories are always destined to be left half way\n",
            "[0.60544676]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNG_EzOCKWeX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}