{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_loading&SavingModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG0ds5ejRP1P"
      },
      "source": [
        "#### Saving and Loading Models\n",
        "We will learn how we can take a trained model, save it, and then load it back to keep training it or use it to perform inference. In particular, we will use transfer learning to train a classifier to classify images of cats and dogs, just like we did in the previous lesson. We will then take our trained model and save it as an HDF5 file, which is the format used by Keras. We will then load this model, use it to perform predictions, and then continue to train the model. Finally, we will save our trained model as a TensorFlow SavedModel and then we will download it to a local disk, so that it can later be used for deployment in different platforms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDNPXwvRRqf_"
      },
      "source": [
        "#### Concepts that will be covered in this Colab\n",
        "1. Saving models in HDF5 format for Keras\n",
        "2. Saving models in the TensorFlow SavedModel format\n",
        "3. Loading models\n",
        "4. Download models to Local Disk\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfsQPUw_Rzst"
      },
      "source": [
        "## Organizing Imports \n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf \n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diPCMvMVSiaX"
      },
      "source": [
        "#### Part 1: Load the Cats vs. Dogs Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBRpr8xWSU9z",
        "outputId": "4685c83e-6af7-47ec-842f-e65ed137ad22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "(train_examples , validation_examples ) ,info = tfds.load(\n",
        "    'cats_vs_dogs' ,\n",
        "    split =['train[:80%]','train[80%:]'],\n",
        "    with_info = True,\n",
        "    as_supervised = True\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/cats_vs_dogs/4.0.0.incompleteFJIYNL/cats_vs_dogs-train.tfrecord\n",
            "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP2drsxOTHOS"
      },
      "source": [
        "The images in the Dogs vs. Cats dataset are not all the same size. So, we need to reformat all images to the resolution expected by MobileNet (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvbdm44VTCsP"
      },
      "source": [
        "def format_image(image , label):\n",
        "  # `hub` image modules exepct their data normalized to the [0,1] range.\n",
        "  image = tf.image.resize(image, (IMAGE_RES,IMAGE_RES))/255\n",
        "  return image,label\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_RES = 224\n",
        "\n",
        "train_batches = train_examples.cache().shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.cache().map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjknJd66Uyt1"
      },
      "source": [
        "#### Part 2: Transfer Learning with TensorFlow Hub\n",
        "We will now use TensorFlow Hub to do Transfer Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CE5JxUhUuFK"
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL, input_shape=(IMAGE_RES,IMAGE_RES,3))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh-Z8gVPVF92"
      },
      "source": [
        "Freeze the variables in the feature extractor layer, so that the training only modifies the final classifier layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHdTmsCWVDiw"
      },
      "source": [
        "feature_extractor.trainable = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2F-IkzVRSD"
      },
      "source": [
        "#### Attach a classification head\n",
        "Now wrap the hub layer in a tf.keras.Sequential model, and add a new classification layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQmPfSUoVQhm",
        "outputId": "33695134-3025-4f44-91a3-2a63f73fa5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             feature_extractor,\n",
        "                             layers.Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szIuM6AyVqHL"
      },
      "source": [
        "#### Train the model\n",
        "We now train this model like any other, by first calling compile followed by fit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h_2Md0TVpWk",
        "outputId": "12fca1c5-79e6-4563-e926-93c51ce3beb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "EPOCHS = 3\n",
        "history = model.fit(train_batches,\n",
        "                    epochs = EPOCHS,\n",
        "                    validation_data =validation_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "    582/Unknown - 45s 78ms/step - loss: 0.0547 - accuracy: 0.9815"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkn5F5wPWWA0"
      },
      "source": [
        "#### Check the predictions\n",
        "Get the ordered list of class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMYx4dO3WRxe"
      },
      "source": [
        "import numpy as np\n",
        "class_names = np.array(info.features['label'].names)\n",
        "class_names"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2rbyPhyWj3z"
      },
      "source": [
        "Run an image batch through the model and convert the indices to class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uynt3ZwFWkjB"
      },
      "source": [
        "image_batch , label_batch = next(iter(train_batches.take(1)))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "predicted_ids = np.argmax(predicted_batch,axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "predicted_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yso9X_akYRKs"
      },
      "source": [
        "Let's look at the true labels and predicted ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOm-dlaqYSK6"
      },
      "source": [
        "print(\"Labels: \", label_batch)\n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyudEptYTwK"
      },
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFap5OSwM0u"
      },
      "source": [
        "#### Part 3: Save as Keras .h5 model\n",
        "Now that we've trained the model, we can save it as an HDF5 file, which is the format used by Keras. Our HDF5 file will have the extension '.h5', and it's name will correpond to the current time stamp."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPHfNhTwPp0"
      },
      "source": [
        "t =time.time()\n",
        "\n",
        "export_path_keras = \"./{}.h5\".format(int(t))\n",
        "print(export_path_keras)\n",
        "\n",
        "model.save(export_path_keras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQM4yDCyH19"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQQGXpMcyIZV"
      },
      "source": [
        "You can later recreate the same model from this file, even if you no longer have access to the code that created the model.\n",
        "\n",
        "This file includes:\n",
        "\n",
        "- The model's architecture\n",
        "- The model's weight values (which were learned during training)\n",
        "- The model's training config (what you passed to `compile`), if any\n",
        "- The optimizer and its state, if any (this enables you to restart training where you left off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ_JGio6yM0E"
      },
      "source": [
        "#### Part 4: Load the Keras .h5 Model\n",
        "We will now load the model we just saved into a new model called reloaded. We will need to provide the file path and the custom_objects parameter. This parameter tells keras how to load the hub.KerasLayer from the feature_extractor we used for transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmdLQMpgyhoS"
      },
      "source": [
        "reloaded = tf.keras.models.load_model( export_path_keras,\n",
        "                # `custom_objects` tells keras how to load a `hub.KerasLayer`\n",
        "                custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "reloaded.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGuBPEmsyuUH"
      },
      "source": [
        "We can check that the reloaded model and the previous model give the same result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8vkfpY7yvY2"
      },
      "source": [
        "result_batch = model.predict(image_batch)\n",
        "reloaded_result_batch = reloaded.predict(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niGbIPzYy-z0"
      },
      "source": [
        "The difference in output should be zero:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp98wcq3y_Zk"
      },
      "source": [
        "(abs(result_batch- reloaded_result_batch)).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjT5iGsjzLYr"
      },
      "source": [
        "As we can see, the reult is 0.0, which indicates that both models made the same predictions on the same batch of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1b4yG8fzQUq"
      },
      "source": [
        "#### Keep Training\n",
        "Besides making predictions, we can also take our reloaded model and keep training it. To do this, you can just train the reloaded as usual, using the .fit method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxw4XFfjzTid"
      },
      "source": [
        "EPOCHS = 3\n",
        "history = reloaded.fit(train_batches,\n",
        "                       epochs= EPOCHS ,\n",
        "                       validation_data = validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwyWhbrmzsH8"
      },
      "source": [
        "#### Part 5: Export as SavedModel\n",
        "\n",
        "You can also export a whole model to the TensorFlow SavedModel format. SavedModel is a standalone serialization format for Tensorflow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. A SavedModel contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying (with TFLite, TensorFlow.js, TensorFlow Serving, or TFHub).\n",
        "\n",
        "The SavedModel files that were created contain:\n",
        "\n",
        "* A TensorFlow checkpoint containing the model weights.\n",
        "* A SavedModel proto containing the underlying Tensorflow graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
        "* The model's architecture config, if available.\n",
        "\n",
        "\n",
        "Let's save our original `model` as a TensorFlow SavedModel. To do this we will use the `tf.saved_model.save()` function. This functions takes in the model we want to save and the path to the folder where we want to save our model. \n",
        "\n",
        "This function will create a folder where you will find an `assets` folder, a `variables` folder, and the `saved_model.pb` file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1jndJQUzxbK"
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_sm = \"./{}\".format(int(t))\n",
        "print(export_path_sm)\n",
        "\n",
        "tf.saved_model.save(model, export_path_sm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvDLuYzR0DI4"
      },
      "source": [
        "!ls {export_path_sm}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umHUGVHJ0LuD"
      },
      "source": [
        "#### Part 6: Load SavedModel\n",
        "Now, let's load our SavedModel and use it to make predictions. We use the tf.saved_model.load() function to load our SavedModels. The object returned by tf.saved_model.load is 100% independent of the code that created it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRAFsp_30OOM"
      },
      "source": [
        "reloaded_sm = tf.saved_model.load(export_path_sm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q3pUfiS0WkB"
      },
      "source": [
        "Now, let's use the reloaded_sm (reloaded SavedModel) to make predictions on a batch of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv6L40GT0XLE"
      },
      "source": [
        "reloaded_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX3p7A5S0iac"
      },
      "source": [
        "We can check that the reloaded SavedModel and the previous model give the same result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JraRVMnZ0i-L"
      },
      "source": [
        "(abs(result_batch - reload_sm_result_batch)).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anM4hLHm0mGL"
      },
      "source": [
        "As we can see, the result is 0.0, which indicates that both models made the same predictions on the same batch of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcKxty8a0vbm"
      },
      "source": [
        "#### Part 7: Loading the SavedModel as a Keras Model\n",
        "The object returned by tf.saved_model.load is not a Keras object (i.e. doesn't have .fit, .predict, .summary, etc. methods). Therefore, you can't simply take your reloaded_sm model and keep training it by running .fit. To be able to get back a full keras model from the Tensorflow SavedModel format we must use the tf.keras.models.load_model function. This function will work the same as before, except now we pass the path to the folder containing our SavedModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7WaDVMF0xLV"
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_sm = \"./{}\".format(int(t))\n",
        "print(export_path_sm)\n",
        "tf.saved_model.save(model,export_path_sm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ohexzbg1EcO"
      },
      "source": [
        "reloaded_sm_keras = tf.keras.models.load_model(\n",
        "    export_pat_sm,\n",
        "    custom_objects = {'KerasLayer':hub.KerasLayer}\n",
        ")\n",
        "\n",
        "reload_sm_keras.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9JIK8je1Xy0"
      },
      "source": [
        "Now, let's use the reloaded_sm)keras (reloaded Keras model from our SavedModel) to make predictions on a batch of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8otrUf4A1ZcN"
      },
      "source": [
        "result_batch = model.predict(image_batch)\n",
        "reload_sm_keras_result_batch = reload_sm_keras.predict(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQkQJ47Q1mIr"
      },
      "source": [
        "We can check that the reloaded Keras model and the previous model give the same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBeYSFyt1m6J"
      },
      "source": [
        "(abs(result_batch - reload_sm_keras_result_batch)).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GbVT43S1q36"
      },
      "source": [
        "#### Part 8: Download your model\n",
        "You can download the SavedModel to your local disk by creating a zip file. We wil use the -r (recursice) option to zip all subfolders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONGw8Nsk1sHX"
      },
      "source": [
        "!zip -r model.zip {export_path_sm}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhoTUH7s10NR"
      },
      "source": [
        "The zip file is saved in the current working directory. You can see what the current working directory is by running:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV0EoDBV104t"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36sSnLAZ13W2"
      },
      "source": [
        "Once the file is zipped, you can download it to your local disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMykIg3M15uo"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./model.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7jpKOqJ16bO"
      },
      "source": [
        "The files.download command will search for files in your current working directory. If the file you want to download is in a directory other than the current working directory, you have to include the path to the directory where the file is located."
      ]
    }
  ]
}